{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting query.hql\n"
     ]
    }
   ],
   "source": [
    "%%writefile query.hql\n",
    "\n",
    "ADD JAR /opt/cloudera/parcels/CDH/lib/hive/lib/hive-contrib.jar;\n",
    "ADD JAR /opt/cloudera/parcels/CDH/lib/hive/lib/hive-serde.jar;\n",
    "\n",
    "USE stackoverflow_;\n",
    "\n",
    "WITH \n",
    "TAG_EX_2016 AS (\n",
    "    SELECT post_type_id,tag\n",
    "    FROM stackoverflow_.posts LATERAL VIEW explode(tags) tagTable AS tag\n",
    "    WHERE Year=2016 and tags IS NOT NULL\n",
    "),\n",
    "TAG_EX_2009 AS (\n",
    "    SELECT post_type_id,tag\n",
    "    FROM stackoverflow_.posts LATERAL VIEW explode(tags) tagTable AS tag\n",
    "    WHERE Year=2009 and tags IS NOT NULL\n",
    "),\n",
    "TAG_COUNT_2016 AS (\n",
    "    SELECT tag, COUNT(post_type_id) AS id_count_2016\n",
    "    FROM TAG_EX_2016\n",
    "    GROUP BY tag\n",
    "    ORDER BY id_count_2016 DESC\n",
    "    LIMIT 10\n",
    "),\n",
    "TAG_COUNT_2009 AS (\n",
    "    SELECT tag, COUNT(post_type_id) AS id_count_2009\n",
    "    FROM TAG_EX_2009\n",
    "    GROUP BY tag\n",
    "    ORDER BY id_count_2009 DESC\n",
    "),\n",
    "TAG_RANKED_2016 AS (\n",
    "    SELECT tag AS tag_2016, id_count_2016, RANK() OVER(ORDER BY id_count_2016 DESC) AS tag_rank_2016\n",
    "    FROM TAG_COUNT_2016\n",
    "),\n",
    "TAG_RANKED_2009 AS (\n",
    "    SELECT tag AS tag_2009, id_count_2009, RANK() OVER(ORDER BY id_count_2009 DESC) AS tag_rank_2009\n",
    "    FROM TAG_COUNT_2009\n",
    ")\n",
    "SELECT tag_2016,tag_rank_2016,tag_rank_2009,id_count_2016,id_count_2009\n",
    "FROM TAG_RANKED_2016,TAG_RANKED_2009\n",
    "WHERE tag_2016=tag_2009\n",
    "ORDER BY tag_rank_2016"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Logging initialized using configuration in jar:file:/usr/local/apache-hive-1.1.0-bin/lib/hive-common-1.1.0.jar!/hive-log4j.properties\n",
      "Added [/opt/cloudera/parcels/CDH/lib/hive/lib/hive-contrib.jar] to class path\n",
      "Added resources: [/opt/cloudera/parcels/CDH/lib/hive/lib/hive-contrib.jar]\n",
      "Added [/opt/cloudera/parcels/CDH/lib/hive/lib/hive-serde.jar] to class path\n",
      "Added resources: [/opt/cloudera/parcels/CDH/lib/hive/lib/hive-serde.jar]\n",
      "OK\n",
      "Time taken: 1.096 seconds\n",
      "Query ID = jovyan_20180311021717_5d8591e2-318a-4150-b0fe-969cccc76fec\n",
      "Total jobs = 10\n",
      "Launching Job 1 out of 10\n",
      "Number of reduce tasks not specified. Estimated from input data size: 1\n",
      "In order to change the average load for a reducer (in bytes):\n",
      "  set hive.exec.reducers.bytes.per.reducer=<number>\n",
      "In order to limit the maximum number of reducers:\n",
      "  set hive.exec.reducers.max=<number>\n",
      "In order to set a constant number of reducers:\n",
      "  set mapreduce.job.reduces=<number>\n",
      "Starting Job = job_1520709033760_0037, Tracking URL = http://b97da810ec8a:8088/proxy/application_1520709033760_0037/\n",
      "Kill Command = /opt/hadoop/bin/hadoop job  -kill job_1520709033760_0037\n",
      "Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1\n",
      "2018-03-11 02:17:56,153 Stage-1 map = 0%,  reduce = 0%\n",
      "2018-03-11 02:18:05,235 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 7.91 sec\n",
      "2018-03-11 02:18:14,017 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 7.91 sec\n",
      "MapReduce Total cumulative CPU time: 7 seconds 910 msec\n",
      "Ended Job = job_1520709033760_0037\n",
      "Launching Job 2 out of 10\n",
      "Number of reduce tasks not specified. Estimated from input data size: 1\n",
      "In order to change the average load for a reducer (in bytes):\n",
      "  set hive.exec.reducers.bytes.per.reducer=<number>\n",
      "In order to limit the maximum number of reducers:\n",
      "  set hive.exec.reducers.max=<number>\n",
      "In order to set a constant number of reducers:\n",
      "  set mapreduce.job.reduces=<number>\n",
      "Starting Job = job_1520709033760_0038, Tracking URL = http://b97da810ec8a:8088/proxy/application_1520709033760_0038/\n",
      "Kill Command = /opt/hadoop/bin/hadoop job  -kill job_1520709033760_0038\n",
      "Hadoop job information for Stage-6: number of mappers: 1; number of reducers: 1\n",
      "2018-03-11 02:18:32,743 Stage-6 map = 0%,  reduce = 0%\n",
      "2018-03-11 02:18:41,800 Stage-6 map = 100%,  reduce = 0%, Cumulative CPU 6.8 sec\n",
      "2018-03-11 02:18:51,495 Stage-6 map = 100%,  reduce = 100%, Cumulative CPU 10.26 sec\n",
      "MapReduce Total cumulative CPU time: 10 seconds 260 msec\n",
      "Ended Job = job_1520709033760_0038\n",
      "Launching Job 3 out of 10\n",
      "Number of reduce tasks determined at compile time: 1\n",
      "In order to change the average load for a reducer (in bytes):\n",
      "  set hive.exec.reducers.bytes.per.reducer=<number>\n",
      "In order to limit the maximum number of reducers:\n",
      "  set hive.exec.reducers.max=<number>\n",
      "In order to set a constant number of reducers:\n",
      "  set mapreduce.job.reduces=<number>\n",
      "Starting Job = job_1520709033760_0039, Tracking URL = http://b97da810ec8a:8088/proxy/application_1520709033760_0039/\n",
      "Kill Command = /opt/hadoop/bin/hadoop job  -kill job_1520709033760_0039\n",
      "Hadoop job information for Stage-2: number of mappers: 1; number of reducers: 1\n",
      "2018-03-11 02:19:08,896 Stage-2 map = 0%,  reduce = 0%\n",
      "2018-03-11 02:19:17,657 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 4.69 sec\n",
      "2018-03-11 02:19:26,230 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 8.33 sec\n",
      "MapReduce Total cumulative CPU time: 8 seconds 330 msec\n",
      "Ended Job = job_1520709033760_0039\n",
      "Launching Job 4 out of 10\n",
      "Number of reduce tasks determined at compile time: 1\n",
      "In order to change the average load for a reducer (in bytes):\n",
      "  set hive.exec.reducers.bytes.per.reducer=<number>\n",
      "In order to limit the maximum number of reducers:\n",
      "  set hive.exec.reducers.max=<number>\n",
      "In order to set a constant number of reducers:\n",
      "  set mapreduce.job.reduces=<number>\n",
      "Starting Job = job_1520709033760_0040, Tracking URL = http://b97da810ec8a:8088/proxy/application_1520709033760_0040/\n",
      "Kill Command = /opt/hadoop/bin/hadoop job  -kill job_1520709033760_0040\n",
      "Hadoop job information for Stage-7: number of mappers: 1; number of reducers: 1\n",
      "2018-03-11 02:19:43,630 Stage-7 map = 0%,  reduce = 0%\n",
      "2018-03-11 02:19:52,227 Stage-7 map = 100%,  reduce = 0%, Cumulative CPU 3.23 sec\n",
      "2018-03-11 02:20:00,740 Stage-7 map = 100%,  reduce = 100%, Cumulative CPU 6.85 sec\n",
      "MapReduce Total cumulative CPU time: 6 seconds 850 msec\n",
      "Ended Job = job_1520709033760_0040\n",
      "Launching Job 5 out of 10\n",
      "Number of reduce tasks not specified. Estimated from input data size: 1\n",
      "In order to change the average load for a reducer (in bytes):\n",
      "  set hive.exec.reducers.bytes.per.reducer=<number>\n",
      "In order to limit the maximum number of reducers:\n",
      "  set hive.exec.reducers.max=<number>\n",
      "In order to set a constant number of reducers:\n",
      "  set mapreduce.job.reduces=<number>\n",
      "Starting Job = job_1520709033760_0041, Tracking URL = http://b97da810ec8a:8088/proxy/application_1520709033760_0041/\n",
      "Kill Command = /opt/hadoop/bin/hadoop job  -kill job_1520709033760_0041\n",
      "Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1\n",
      "2018-03-11 02:20:19,289 Stage-3 map = 0%,  reduce = 0%\n",
      "2018-03-11 02:20:27,883 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 2.51 sec\n",
      "2018-03-11 02:20:37,483 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 7.6 sec\n",
      "MapReduce Total cumulative CPU time: 7 seconds 600 msec\n",
      "Ended Job = job_1520709033760_0041\n",
      "Launching Job 6 out of 10\n",
      "Number of reduce tasks not specified. Estimated from input data size: 1\n",
      "In order to change the average load for a reducer (in bytes):\n",
      "  set hive.exec.reducers.bytes.per.reducer=<number>\n",
      "In order to limit the maximum number of reducers:\n",
      "  set hive.exec.reducers.max=<number>\n",
      "In order to set a constant number of reducers:\n",
      "  set mapreduce.job.reduces=<number>\n",
      "Starting Job = job_1520709033760_0042, Tracking URL = http://b97da810ec8a:8088/proxy/application_1520709033760_0042/\n",
      "Kill Command = /opt/hadoop/bin/hadoop job  -kill job_1520709033760_0042\n",
      "Hadoop job information for Stage-8: number of mappers: 1; number of reducers: 1\n",
      "2018-03-11 02:20:54,897 Stage-8 map = 0%,  reduce = 0%\n",
      "2018-03-11 02:21:03,445 Stage-8 map = 100%,  reduce = 0%, Cumulative CPU 4.11 sec\n",
      "2018-03-11 02:21:13,171 Stage-8 map = 100%,  reduce = 100%, Cumulative CPU 9.62 sec\n",
      "MapReduce Total cumulative CPU time: 9 seconds 620 msec\n",
      "Ended Job = job_1520709033760_0042\n",
      "Stage-12 is filtered out by condition resolver.\n",
      "Stage-13 is selected by condition resolver.\n",
      "Stage-4 is filtered out by condition resolver.\n",
      "Execution log at: /tmp/jovyan/jovyan_20180311021717_5d8591e2-318a-4150-b0fe-969cccc76fec.log\n",
      "2018-03-11 02:21:21\tStarting to launch local task to process map join;\tmaximum memory = 477626368\n",
      "2018-03-11 02:21:22\tDump the side-table for tag: 0 with group count: 10 into file: file:/tmp/jovyan/93e1cc78-8358-408c-a9b6-4630b9bda835/hive_2018-03-11_02-17-37_250_7732119616351853027-1/-local-10012/HashTable-Stage-10/MapJoin-mapfile10--.hashtable\n",
      "2018-03-11 02:21:22\tUploaded 1 File to: file:/tmp/jovyan/93e1cc78-8358-408c-a9b6-4630b9bda835/hive_2018-03-11_02-17-37_250_7732119616351853027-1/-local-10012/HashTable-Stage-10/MapJoin-mapfile10--.hashtable (541 bytes)\n",
      "2018-03-11 02:21:22\tEnd of local task; Time Taken: 1.63 sec.\n",
      "Execution completed successfully\n",
      "MapredLocal task succeeded\n",
      "Launching Job 8 out of 10\n",
      "Number of reduce tasks is set to 0 since there's no reduce operator\n",
      "Starting Job = job_1520709033760_0043, Tracking URL = http://b97da810ec8a:8088/proxy/application_1520709033760_0043/\n",
      "Kill Command = /opt/hadoop/bin/hadoop job  -kill job_1520709033760_0043\n",
      "Hadoop job information for Stage-10: number of mappers: 1; number of reducers: 0\n",
      "2018-03-11 02:21:37,033 Stage-10 map = 0%,  reduce = 0%\n",
      "2018-03-11 02:21:45,586 Stage-10 map = 100%,  reduce = 0%, Cumulative CPU 4.97 sec\n",
      "MapReduce Total cumulative CPU time: 4 seconds 970 msec\n",
      "Ended Job = job_1520709033760_0043\n",
      "Launching Job 9 out of 10\n",
      "Number of reduce tasks determined at compile time: 1\n",
      "In order to change the average load for a reducer (in bytes):\n",
      "  set hive.exec.reducers.bytes.per.reducer=<number>\n",
      "In order to limit the maximum number of reducers:\n",
      "  set hive.exec.reducers.max=<number>\n",
      "In order to set a constant number of reducers:\n",
      "  set mapreduce.job.reduces=<number>\n",
      "Starting Job = job_1520709033760_0044, Tracking URL = http://b97da810ec8a:8088/proxy/application_1520709033760_0044/\n",
      "Kill Command = /opt/hadoop/bin/hadoop job  -kill job_1520709033760_0044\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hadoop job information for Stage-5: number of mappers: 1; number of reducers: 1\n",
      "2018-03-11 02:22:03,942 Stage-5 map = 0%,  reduce = 0%\n",
      "2018-03-11 02:22:12,477 Stage-5 map = 100%,  reduce = 0%, Cumulative CPU 3.41 sec\n",
      "2018-03-11 02:22:21,103 Stage-5 map = 100%,  reduce = 100%, Cumulative CPU 7.59 sec\n",
      "MapReduce Total cumulative CPU time: 7 seconds 590 msec\n",
      "Ended Job = job_1520709033760_0044\n",
      "MapReduce Jobs Launched: \n",
      "Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 13.54 sec   HDFS Read: 834998 HDFS Write: 283234 SUCCESS\n",
      "Stage-Stage-6: Map: 1  Reduce: 1   Cumulative CPU: 10.26 sec   HDFS Read: 145098 HDFS Write: 67863 SUCCESS\n",
      "Stage-Stage-2: Map: 1  Reduce: 1   Cumulative CPU: 8.33 sec   HDFS Read: 287127 HDFS Write: 354 SUCCESS\n",
      "Stage-Stage-7: Map: 1  Reduce: 1   Cumulative CPU: 6.85 sec   HDFS Read: 71630 HDFS Write: 67863 SUCCESS\n",
      "Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 7.6 sec   HDFS Read: 6465 HDFS Write: 364 SUCCESS\n",
      "Stage-Stage-8: Map: 1  Reduce: 1   Cumulative CPU: 9.62 sec   HDFS Read: 73974 HDFS Write: 74637 SUCCESS\n",
      "Stage-Stage-10: Map: 1   Cumulative CPU: 4.97 sec   HDFS Read: 79650 HDFS Write: 391 SUCCESS\n",
      "Stage-Stage-5: Map: 1  Reduce: 1   Cumulative CPU: 7.59 sec   HDFS Read: 5458 HDFS Write: 188 SUCCESS\n",
      "Total MapReduce CPU Time Spent: 1 minutes 8 seconds 760 msec\n",
      "OK\n",
      "javascript\t1\t5\t2771\t192\n",
      "java\t2\t2\t2033\t243\n",
      "android\t3\t52\t1809\t25\n",
      "php\t4\t3\t1673\t215\n",
      "python\t5\t11\t1585\t108\n",
      "c#\t6\t1\t1519\t423\n",
      "html\t7\t14\t1212\t84\n",
      "jquery\t8\t8\t1167\t141\n",
      "ios\t9\t186\t914\t7\n",
      "css\t10\t20\t801\t59\n",
      "Time taken: 285.0 seconds, Fetched: 10 row(s)\n"
     ]
    }
   ],
   "source": [
    "! hive -f query.hql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
